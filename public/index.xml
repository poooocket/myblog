<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hi，我是蔡克梅</title>
    <link>https://poooocket.github.io/myblog/</link>
    <description>Recent content on Hi，我是蔡克梅</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://poooocket.github.io/myblog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>咕咕记</title>
      <link>https://poooocket.github.io/myblog/guguji/</link>
      <pubDate>Mon, 21 Apr 2025 10:59:58 +0800</pubDate>
      <guid>https://poooocket.github.io/myblog/guguji/</guid>
      <description>最近迷上了一档名为 All-In with Chamath, Jason, Sacks &amp;amp; Friedberg的播客节目，节目邀请行业资深人士，围绕经济、政治、科技、社会等多方面话题展开深度探讨。每期播客时长都超过一小时，对我来说既是享受，也是挑战。很多地方我听不太懂，尤其是俚语和玩笑部分。为了更好地理解播客内容，我希望能将播客转写成文本。&#xA;已有解决方案调研 市场上有很多音频转写和AI摘要工具，我主要调研了以下三个产品：通义听悟、Podwise、NotebookLM&#xA;我想要有一个能帮助我渐进式理解播客内容的工具，理想的使用流程是：&#xA;播客摘要 → 结构化笔记（重要观点 + 举例、数据等说明）→ 精听感兴趣的部分。&#xA;目前市面上的工具还不够理想：&#xA;Podwise 功能接近，但交互体验不便：Mindmap 和转录文本分在两个 tab，需要频繁切换查看；Mindmap节点默认收起，手动展开很麻烦；最关键的是免费版每月仅支持 4 个播客生成 AI 内容，且不支持导出。 通义听悟 AI生成的内容啰嗦、缺乏结构，阅读体验差。 NotebookLM 的模型能力很强，摘要和结构化笔记重点明确且自带引用，但交互复杂，不支持音频与文本联动，不能边听边看，而且上传音频有 200M 限制，无法处理多数 2 小时以上的播客。 因此，我打算根据自己的使用习惯，自制一个播客小助手，打造更符合个人节奏和理解路径的工具，顺便学习一下相关技术。&#xA;我计划使用 Streamlit 快速搭建播客小助手的原型，聚焦以下核心功能：&#xA;播客RSS解析 → 下载音频 → 自动转写 → 说话人分离 → 摘要生成 → 结构化笔记展示。&#xA;技术栈调研与选择 音频转写方案 Whisper&#xA;Whisper 是 OpenAI 开源的语音识别模型，基于 Transformer 自回归架构，具备以下核心能力：&#xA;支持多语言识别，包括中文和中英文混合语音； 语言自动检测； 支持将非英语语音直接翻译为英文文本； 自动根据语速与停顿进行文本切分，并添加时间戳，可直接用于字幕生成。 Whisper 提供 5 个模型尺寸（tiny、base、small、medium、large），以及优化推理速度的 large-turbo 版本，分别测试了tiny、base、small和turbo模型，结果：&#xA;tiny、base、small 在英文语音场景下识别准确率和速度表现良好但中文识别率相对偏低； turbo 对中文及中英混合识别准确率显著提高，但存在两个问题：默认输出不带标点；部分输出为繁体字。上述问题可通过参数 initial_prompt=&amp;ldquo;以下是普通话句子。&amp;rdquo; 解决，实测有效。 Whisper衍生版本</description>
    </item>
    <item>
      <title>车辆故障反馈信息分析工具</title>
      <link>https://poooocket.github.io/myblog/info_extract/</link>
      <pubDate>Sun, 30 Jun 2024 10:59:58 +0800</pubDate>
      <guid>https://poooocket.github.io/myblog/info_extract/</guid>
      <description>&#xA;车主通过社交媒体、论坛、客服热线等渠道反馈车辆问题，其中包含大量故障信息。这些反馈对于产品优化、售后服务和质量改进具有重要价值。然而，由于数据来源多样，反馈内容非结构化，往往包含主观描述、行业术语、口语化表达甚至错别字，使得传统的信息提取和分类方法难以高效处理。&#xA;目前，故障反馈信息的分析主要面临以下挑战：&#xA;数据格式不统一：不同渠道的数据结构不同，例如社交媒体上的短文本、客服记录的对话文本、论坛中的长篇描述等。 自然语言表达复杂：用户可能使用模糊或隐含表达，如“刹车感觉有点软”可能指向刹车系统异常。 高质量标注数据稀缺：传统机器学习方法依赖大量标注数据，而领域专家的标注成本较高，且难以标准化。 本项目利用LLM实现车辆故障反馈信息的自动化分析，包括关键信息抽取和故障分类。通过整合用户在社交媒体、论坛、客服记录等渠道的非结构化反馈，识别故障部件、故障类型及症状描述，并将其归类至相应的故障类别。可应用于售后客服支持、质量分析、产品改进等多个场景，帮助车企和维修服务商高效分析用户反馈，优化产品质量和售后服务体验。&#xA;信息抽取方法的演进 传统方法：规则匹配 最早的信息抽取方法基于规则，例如通过关键词匹配或正则表达式提取故障信息。这种方法在格式规范的场景下有效，但难以应对复杂多变的用户表达，且规则的维护成本高。&#xA;统计学习与深度学习方法&#xA;随着NLP技术的发展，基于机器学习的模型逐步取代了规则方法，例如：&#xA;BiLSTM-CRF：可以自动学习文本特征，广泛用于命名实体识别（NER）任务，如提取故障部件（发动机、刹车）或故障类型（抖动、异响）。但该方法仍需大量标注数据，并难以捕捉长距离依赖关系。 BERT-CRF：结合了预训练语言模型BERT的上下文理解能力，与CRF序列标注能力，在信息抽取任务上表现更优。然而，它仍然依赖高质量标注数据，并且难以泛化到不同的车辆品牌和车型。 基于LLM的方法及优势 近年来，大型语言模型（LLM）如GPT、Llama3等在自然语言处理任务上展现了强大的能力，能够在低标注甚至零样本的情况下进行高效的信息抽取。相比传统方法，LLM的优势包括：&#xA;无需大量标注数据：可通过Few-shot或Zero-shot学习，从少量示例中泛化出有效的信息提取模式。 强大的上下文理解能力：能够识别语境中的隐含信息，如“踩油门没反应”可被识别为“动力系统异常”。 支持端到端处理：可同时完成信息抽取、分类与摘要，提高数据处理效率。 在车辆故障反馈分析中，我们可以利用LLM进行：&#xA;故障关键信息提取：从用户反馈中抽取故障部件、故障类型、故障情境。 故障部位分类：将反馈内容按受影响部件（发动机、刹车、电池等）进行分类。 具体实施方式 基于Llama-3-8B微调关键信息提取模型 采集用户反馈数据，清洗无效数据。&#xA;利用 LLM 进行初步标注**，**设计信息抽取任务提示模板，让GPT从用户反馈数据中抽取关键信息，信息抽取任务提示模板：&#xA;&amp;#34;&amp;#34;&amp;#34; 你是一个汽车质量问题抽取模型，根据我输入的内容，从中抽取故障部位、故障类型和故障情境信息。 输出中文，仅JSON格式，不要其他内容，格式如下： [{{&amp;#34;故障部位&amp;#34;: &amp;#34;&amp;lt;故障部位1&amp;gt;&amp;#34;, &amp;#34;故障类型&amp;#34;: &amp;#34;&amp;lt;故障类型1&amp;gt;&amp;#34;, &amp;#34;故障情境&amp;#34;: &amp;#34;&amp;lt;故障情境1&amp;gt;&amp;#34;}}, {{&amp;#34;故障部位&amp;#34;: &amp;#34;&amp;lt;故障部位2&amp;gt;&amp;#34;, &amp;#34;故障类型&amp;#34;: &amp;#34;&amp;lt;故障类型2&amp;gt;&amp;#34;, &amp;#34;故障情境&amp;#34;: &amp;#34;&amp;lt;故障情境2&amp;gt;&amp;#34;}}, ... ] 输入:{}。 &amp;#34;&amp;#34;&amp;#34; 对抽取的信息进行人工检查和修正，构建训练数据集，保证数据集的准确性和均衡性。&#xA;将修正后的数据集输入基座模型进行微调训练，基座模型采用Llama-3-8B，微调方式采用LoRA（Low-Rank Adaptation），LoRA是一种高效的参数微调技术，冻结预训练模型权重，通过低秩分解模拟参数更新，仅对额外极少的参数进行训练便可实现模型高效的微调。将训练后的LoRA模型与基座模型合并为独立的新模型，保存新模型结构和参数，便于后续部署和使用。&#xA;构建分类标签字典，基于大语言模型对抽取的故障信息进行分类 构建一个专业的智能车零部件字典作为分类标签，考虑到用户反馈的多样性和模糊性，避免分类标签不完备，引入特定标签，包括“交付/售后服务”、和“其他”。&#xA;构建故障信息分类few-shots示例，设计分类提示模板，将抽取的关键信息、分类标签字典和分类示例输入大语言模型，分类提示模板：&#xA;&amp;#34;&amp;#34;&amp;#34; 你是一个汽车零部件分类专家，参考映射示例将我输入的内容映射到零部件标签。 仅输出唯一正确的标签文字，不要其他内容。 零部件标签：{} 映射示例：{} 输入：{} &amp;#34;&amp;#34;&amp;#34; 结果可视化 计算分类关键信息的可视化数据，通过图数据技术和力导向布局技术构建故障信息节点-边图可视化数据，将节点分类并为每个类型分配颜色，计算节点度中心性表示节点权重，并根据权重调整节点面积，指定连接方向从故障部位分类指向故障类型，使用eCharts-graph来渲染数据，最终可视化效果如下图。&#xA;总结 本项目通过LLM实现车辆故障反馈信息的自动化分析，显著提升了故障信息提取、分类的效率，后续在实用性上有进一步的优化空间，包括：&#xA;集成多数据源：扩展数据采集渠道，整合客服记录、维修工单、车载诊断数据（OBD）等信息，实现更全面的故障分析。 与企业现有系统对接：通过 API 或插件的方式，让本系统无缝对接现有售后管理系统，提升企业落地效率。 </description>
    </item>
    <item>
      <title>智能车配置趋势分析工具</title>
      <link>https://poooocket.github.io/myblog/config_analysis/</link>
      <pubDate>Mon, 30 Oct 2023 10:59:58 +0800</pubDate>
      <guid>https://poooocket.github.io/myblog/config_analysis/</guid>
      <description>背景 智能汽车行业竞争越来越激烈，更新迭代非常快，OEM、Tier1、新势力都在卷配置，比如智驾、激光雷达、中央计算、域控座舱等等。 很多企业在产品规划时，依然依赖有限的人力调研和静态竞品对比，效率太低。&#xA;目标 打造一款智能车配置趋势分析工具，通过自动化采集行业竞品车型数据，结合智能分析模型，动态洞察智能配置的发展趋势，助力产品规划和战略决策。&#xA;过程与方法 数据采集 从开放平台平台自动化采集车型配置数据，在采集过程中遇到了数据结构复杂、格式异构的挑战，针对这些挑战，我设计了一个可扩展的自动化采集框架，实现高质量结构化数据获取。具体包括：&#xA;1. 多层嵌套表格结构解析&#xA;配置页面存在大量 HTML 嵌套表格，包含车型信息、年款、选配包等多级结构。系统通过深度解析 DOM 节点，动态识别并提取不同层级的配置模块，保证数据采集的完整性。&#xA;2. 异构数据结构自动适配&#xA;面对价格行、车型标签、标准配置项等结构不一致的行数据，设计了标签引导的解析逻辑，自动识别并兼容不同的表格模式，保障了多样化结构统一入库。&#xA;3. 表结构转换与清洗&#xA;原始网页以车型为单位分散展示，不利于数据分析。采集后数据自动规整为一个表格，提升了后续分析的可用性。&#xA;4. 增量采集机制&#xA;支持基于 SeriesID 的断点续采与增量更新机制，避免重复爬取，提高了采集效率并增强了系统的稳定性，便于大规模车型数据的周期性更新与扩展。&#xA;数据预处理 字段提取&#xA;利用正则表达式提取车型名称、年款信息和配置项名称，提升数据的结构化程度。 针对稀疏字段（如选装包模块）做结构拆解与单独存储，便于后续定向特征提取与分析。 字段清洗与标准化&#xA;移除无效字符（如图标、空白符号等），提升字段内容纯净度。 统一关键配置项的命名规范（如芯片名称、远程控制功能等），以提高横向对比的一致性。 字段数值化处理&#xA;将价格字段由字符串格式转换为数值格式，便于后续价格区间划分与分析。 数据探索与可视化交互设计 工具选型&#xA;前端框架：Streamlit&#xA;具备 Python 原生支持、轻量部署和组件丰富等优势，能够快速构建交互式数据分析界面。&#xA;可视化组件：st_echarts&#xA;基于 Apache ECharts 封装的 Streamlit 插件，支持高度定制化图表设计，同时提供图表点击事件回传功能，便于通过图表交互行为（如点击条形图中的年款/价格项）驱动后续的表格筛选与展示，实现“图表即筛选器”的探索式数据分析体验。&#xA;数据概览&#xA;对数据进行基础统计与可视化分析：&#xA;**基础信息展示：**包括厂商数量，车型数量，配置数量全局指标，展示整体数据规模与覆盖范围。 **年款及价格分布：**通过堆叠柱形图展示各年款车型在不同价格区间的分布情况，便于观察主力价格段及趋势变化。 **品牌-车型层级结构：**通过旭日图展示厂商与旗下车型的从属关系，便于观察品牌布局及深度。 图表交互联动： 图表支持点击筛选功能，可直接过滤下方列表数据，快速聚焦感兴趣的品牌、车型或价格区间。 数据分布&#xA;支持任意字段的数据分布分析与缺失情况可视化：&#xA;通过字段选择器选定任意字段，展示其值频分布。 图表自动计算并标注缺失值比例，辅助识别数据质量问题。 柱状图支持点击筛选操作，联动更新数据列表，实现按字段值的快速定位与聚焦。 趋势提取与选型对比 围绕公司重点关注的智能驾驶与智能座舱方向，开展配置项渗透率趋势分析与选型策略比较，形成对智能配置发展路径的结构化认知，辅助产品规划与技术路线制定&#xA;分析主题与字段筛选&#xA;与业务方沟通，确定核心关注点为 配置演进趋势与品牌选型差异**，**据此筛选出相关配置字段，聚焦辅助驾驶、感知硬件、座舱交互等模块。&#xA;数据处理&#xA;渗透率计算：&#xA;对每个配置字段，若存在有效值则标记为 1，否则为 0；再按年款或价格区间进行分组，计算均值，得出配置项在该分组下的渗透率水平。</description>
    </item>
    <item>
      <title>整车OTA全链路体验设计（平台端 × 车机端 × 手机端）</title>
      <link>https://poooocket.github.io/myblog/ota/</link>
      <pubDate>Mon, 30 May 2022 10:59:58 +0800</pubDate>
      <guid>https://poooocket.github.io/myblog/ota/</guid>
      <description>随着智能汽车技术的发展，OTA（Over-The-Air）远程升级已成为车企提升产品迭代效率与用户体验的关键手段。用户对升级的关注，正从以往的“技术可行性”转向“体验友好性”，对提示的清晰度、操作的便捷性以及升级结果的可感知性提出了更高要求。&#xA;本项目围绕整车OTA升级流程，系统梳理了平台端、车机端和手机端的核心功能和关键体验，从零到一系统性构建了覆盖平台端、车机端与手机端的OTA体验闭环。&#xA;业务链路调研&#xA;平台端&#xA;用户角色：运营人员、产品经理、技术支持等。&#xA;核心任务：创建整车版本基线（零件模块版本软件组合）；创建OTA升级任务；配置升级策略（目标基线、出发前置条件等）；监控升级执行状态，快速定位失败任务与问题车辆。&#xA;设计目标：降低配置复杂度，提升任务创建效率；支持升级策略的模块化与复用，提升操作便捷性；提供清晰的任务监控数据可视化界面。&#xA;车机端&#xA;用户角色：车主或驾驶员。&#xA;使用场景：收到升级提示；查看版本变更信息；在确保不影响日常用车的前提下，决定是否立即升级或预约；升级过程中了解当前进度和系统状态。&#xA;设计目标：提升OTA提示的可感知性；提供便捷的预约升级入口，使升级不打扰日常用车；提供清晰的升级状态反馈，减少用户对升级过程的不确定和焦虑。&#xA;手机端&#xA;用户角色：车主，通过App远程了解/控制车辆升级状态。&#xA;使用场景：收到OTA推送通知；在App中查看车辆当前版本与升级内容；设置升级时间或远程触发升级；查看升级状态反馈。&#xA;设计目标：升级通知推送；车控页面增加OTA状态组件，可实时查看升级状态，提升信息透明度；支持版本变更信息查看、升级预约、远程升级操作。&#xA;总结&#xA;本次OTA体验设计项目聚焦于“平台端—车机端—手机端”三大核心触点，分别面向企业运营人员与终端用户的不同需求，系统性梳理并优化了各端关键流程与交互节点。平台端强调任务配置的效率与过程可控性，车机端与手机端则聚焦于升级流程的可感知性、易用性与用户信任感，最终构建出一套逻辑闭环、协同统一的OTA体验体系。&#xA;同时在设计过程中构建了统一的设计语言与组件体系，既提升了跨端体验一致性与交付效率，也为云平台的多业务扩展提供了可持续、可复用的设计基础。</description>
    </item>
  </channel>
</rss>
